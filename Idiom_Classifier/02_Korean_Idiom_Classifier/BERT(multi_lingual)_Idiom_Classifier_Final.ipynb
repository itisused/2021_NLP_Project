{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20211019_BERT(multi_lingual)_Idiom_Classifier_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "700abd0a16144906ae0060b498bf6162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3501b0ea7124bbd89055ffe1de0d1c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_493ac1f267f24f85b719ded49934e746",
              "IPY_MODEL_f3c7fcdb77f34e25921a52ba836caf84",
              "IPY_MODEL_644c9126d938477d9beea2d5b222b181"
            ]
          }
        },
        "a3501b0ea7124bbd89055ffe1de0d1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "493ac1f267f24f85b719ded49934e746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6944d9102f34d71852190dfda7eead5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d01561bc73d43cd88bfe72a28048fd1"
          }
        },
        "f3c7fcdb77f34e25921a52ba836caf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42e12a6362eb46abadbd2f2bbceb8e39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddbd33aa675b4d94973af0c383133043"
          }
        },
        "644c9126d938477d9beea2d5b222b181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97490835ada74e47859533581fd9dd35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 13.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bfa2690e8ac405a84ef87d4da821449"
          }
        },
        "a6944d9102f34d71852190dfda7eead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d01561bc73d43cd88bfe72a28048fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42e12a6362eb46abadbd2f2bbceb8e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddbd33aa675b4d94973af0c383133043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97490835ada74e47859533581fd9dd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bfa2690e8ac405a84ef87d4da821449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ea85632c69d48f1afcfcd1930779ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_21c1e9340c284689967087a97c0f7d30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a576e08685a44c90839c12cc28c9c44a",
              "IPY_MODEL_980c1d37218c488e8c51dcd2517c3507",
              "IPY_MODEL_303d426f5dee4f63b15a034d11c152b5"
            ]
          }
        },
        "21c1e9340c284689967087a97c0f7d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a576e08685a44c90839c12cc28c9c44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a25b863106594f73987e76c258f39631",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9068904d8fc64a0299d6be2d6efcba51"
          }
        },
        "980c1d37218c488e8c51dcd2517c3507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5af9cef0eaa341bc9599243bc71c9daf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea4d38fd6963432992b2644312b34228"
          }
        },
        "303d426f5dee4f63b15a034d11c152b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b145a0e915e644288078aa08908b8823",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 5.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2a400c93b6c4003bf71e21392691599"
          }
        },
        "a25b863106594f73987e76c258f39631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9068904d8fc64a0299d6be2d6efcba51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5af9cef0eaa341bc9599243bc71c9daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea4d38fd6963432992b2644312b34228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b145a0e915e644288078aa08908b8823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2a400c93b6c4003bf71e21392691599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "541b9048e0bb42f18c4c63b4cd9b1ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2dc016ceffb641b0b1a0a827a091258e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2774c2fc5ea443396ce710fb0575ef3",
              "IPY_MODEL_69f9ef83390c45e38700683c01b9f30b",
              "IPY_MODEL_98f19768b2b143aa87b38952bb0b2560"
            ]
          }
        },
        "2dc016ceffb641b0b1a0a827a091258e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2774c2fc5ea443396ce710fb0575ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_112c4965cc4c47f4992de4e89e8e1e76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8820ed23f207428a9daa22a18ee13c98"
          }
        },
        "69f9ef83390c45e38700683c01b9f30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_273a965090684e7895a3d8abcc1c0a80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a721774e6174273bb3cb45fab11c25f"
          }
        },
        "98f19768b2b143aa87b38952bb0b2560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b90afa24eaf841ea9006c392ccf209b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 669B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08dd33675a064578ab413cde352c264e"
          }
        },
        "112c4965cc4c47f4992de4e89e8e1e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8820ed23f207428a9daa22a18ee13c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "273a965090684e7895a3d8abcc1c0a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a721774e6174273bb3cb45fab11c25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b90afa24eaf841ea9006c392ccf209b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08dd33675a064578ab413cde352c264e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15d19606ace34666870f39b64c9c5941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47ca6cef0e4b4cca9fb63d42e87ed6bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aadf86b54df944ab89e2d51002cce1f5",
              "IPY_MODEL_f3f9a4b709874501a48e37b06caea424",
              "IPY_MODEL_224156d8a7b44fd7a25497770229b59c"
            ]
          }
        },
        "47ca6cef0e4b4cca9fb63d42e87ed6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aadf86b54df944ab89e2d51002cce1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa9e6fecd6d24d15bd11c905d661971b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fa34294a35f4acb8b0f56725ac994ad"
          }
        },
        "f3f9a4b709874501a48e37b06caea424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e462544d05334bcc8ed82477168c8e60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1961828,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1961828,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86029eeff2d74ff59d0a6b541c901319"
          }
        },
        "224156d8a7b44fd7a25497770229b59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b476a57efb554d5e8e9879d5272a6531",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 4.89MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d68ab5c6b3e448a85184e0c3d1a57ce"
          }
        },
        "aa9e6fecd6d24d15bd11c905d661971b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fa34294a35f4acb8b0f56725ac994ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e462544d05334bcc8ed82477168c8e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86029eeff2d74ff59d0a6b541c901319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b476a57efb554d5e8e9879d5272a6531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d68ab5c6b3e448a85184e0c3d1a57ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10f0fb43a4ee4b8a9529ca4332d14ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1e11df604464c759aec67a397c90955",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3fadae2265f47929b85d237bf79d9da",
              "IPY_MODEL_b2b47a6e29ac4a36843dd4b0da983770",
              "IPY_MODEL_01d1e416dd5d4d3bb268b5361eb11799"
            ]
          }
        },
        "e1e11df604464c759aec67a397c90955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3fadae2265f47929b85d237bf79d9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e100fa10d2884e078800c7cc6f6465cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18e64c069f98494e9d38696a34d86221"
          }
        },
        "b2b47a6e29ac4a36843dd4b0da983770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2928be1e71194537a54d5c496369eb7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_348df742e8fa4163af74f013de78f08e"
          }
        },
        "01d1e416dd5d4d3bb268b5361eb11799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6612e954d5ad4733b74031a2b4e3efe6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:24&lt;00:00, 30.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_213b0a1bad0d4c5b842cf41bfde798c8"
          }
        },
        "e100fa10d2884e078800c7cc6f6465cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18e64c069f98494e9d38696a34d86221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2928be1e71194537a54d5c496369eb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "348df742e8fa4163af74f013de78f08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6612e954d5ad4733b74031a2b4e3efe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "213b0a1bad0d4c5b842cf41bfde798c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoaMYuhb1NZ3"
      },
      "source": [
        "# **BERT(multi-lingual) 기반의 관용구 분류기 (Hugging Face Pytorch ver.)**\n",
        "Idiom Classifier base BERT(multi lingual) with Hugging Face BERT Pytorch ver.\n",
        "\n",
        "- 최종 정리 일시: 2021.10.19\n",
        "\n",
        "- Reference Code: [네이버 영화리뷰 감성분석 (Colab)](https://colab.research.google.com/drive/1tIf0Ugdqg4qT7gcxia3tL7und64Rv1dP#scrollTo=P58qy4--s5_x&uniqifier=1)\n",
        "\n",
        " - 위 코드가 네이버 영화 리뷰를 긍/부정으로 나누는 Binary Classification이기 때문에 관용구를 Yes/No로 분류하는 관용구 분류기와 Dataset만 다를 뿐 기본적으로 모두 구조는 동일\n",
        " - 기본적인 전체 코드는 유지한 채, 데이터와 이에 맞춰 일부 파라미터를 변경하여 관용구 분류기를 구현\n",
        "\n",
        "\n",
        "* KoBERT or KoGPT2의 버전과는 다르게 새로운 데이터셋에 대해 관용구를 예측하는 코드는 수록되어 있지 않음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uauMwcC3LaI"
      },
      "source": [
        "# **1. 환경 설정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poDtWVXqoxkm",
        "outputId": "2558ebe1-a040-4c5a-9bc7-283e87a59476"
      },
      "source": [
        "# 경로 설정(Colab에서 진행한 경우)\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/2021_NLP_Project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/2021_NLP_Project'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bjA--8l4Amb"
      },
      "source": [
        "## 1-1) 변수 설정\n",
        "\n",
        "- 일부 파라미터들 중 중복되는 몇 가지 파라미터에 대해 변수로 처리하고자 추가\n",
        "\n",
        " - `max_len_value`: 입력 토큰의 최대 시퀀스 길이 (`MAX_LEN`의 입력 값)\n",
        " - `bert_model_name`: 분류를 위한 BERT 모델 생성 (`BertForSequenceClassification.from_pretrained`의 입력 값)\n",
        " - `train_test_split_ratio`: train/test 분리 비율 (`train_test_split`의 입력 값)\n",
        " - `train_val_split_ratio `: 훈련셋과 검증셋으로 분리 (`train_test_split`의 입력 값)\n",
        "   - train 데이터의 train/validation 분리 비율로 약 5000개:400개로 분리하기 위해 설정\n",
        "   - 어텐션 마스크를 훈련셋과 검증셋으로 분리 에도 사용\n",
        " - `batch_size_value`: 배치 사이즈 (`batch_size`의 입력 값)\n",
        " - `learning_rate`: 옵티마이저 설정 (`AdamW`의 입력 값)\n",
        "   - 처음 default는 2e-5 (관용구 분류기의 경우 이를 변경하여 성능을 끌어올렸음)\n",
        " - `epochs_value`: 에폭수 (`epochs`의 입력값)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0g8szFqReWd"
      },
      "source": [
        "max_len_value = 64\n",
        "bert_model_name = 'bert-base-multilingual-cased'\n",
        "train_test_split_ratio = 0.2\n",
        "train_val_split_ratio = 0.07\n",
        "batch_size_value = 64\n",
        "learning_rate = 1e-5\n",
        "epochs_value = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCP2oWGKn4a"
      },
      "source": [
        "## 1-2) Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSAtRhY8QoTL",
        "outputId": "c14be3ed-c033-40b9-d5f7-28185f3aebb7"
      },
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 28.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJkM0-2slW_r"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import pickle\n",
        "# from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFxJojiK08-l"
      },
      "source": [
        "# **2. 전처리 - 훈련셋**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDYuwxDoLKNC"
      },
      "source": [
        "## 2-1) Dataset Load\n",
        "\n",
        "- Step 2) Dataset\n",
        "```python\n",
        "with open('./data/final_idiom_dataset_for_ko.pkl', 'rb') as f:\n",
        "```\n",
        "> 한-영 관용구 기계번역을 위한 NMT 학습 방법\n",
        "\n",
        "    - 위 논문에서 사용한 한국어 관용구 Dataset 3,376개\n",
        "    - AI Hub의 한-영 번역(병렬) 말뭉치에서 관용구가 없는 문장 임의로 3,376개 추출\n",
        "\n",
        "- Step 3) Dataset Case 1\n",
        "```python\n",
        "with open('./data/train_11710.pkl', 'rb') as f:\n",
        "```\n",
        "    - 5,855개(관용구 o) + 5,855개(관용구 x)로 테스트 해보기\n",
        "    - 검증셋: 1,500개(관용구 o) + 1,500개(관용구 x)\n",
        "\n",
        "- Step 3) Dataset Case 2\n",
        "```python\n",
        "with open('./data/train_34614.pkl', 'rb') as f:\n",
        "```\n",
        "    - 17,307(관용구 o) + 17,307(관용구 x)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IrbCCtnosLp"
      },
      "source": [
        "# 파일 로드 (경로는 각자 상황에 맞게 설정할 것!)\n",
        "with open('./data/final_idiom_dataset_for_ko.pkl', 'rb') as f:\n",
        "  corpus = pickle.load(f)\n",
        "\n",
        "# with open('./data/train_34614.pkl', 'rb') as f:\n",
        "#   corpus = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHtwgCu1puzO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "2a8e7f6b-6237-4e05-ff9b-271ae8b4a1d1"
      },
      "source": [
        "# Dataset을 불러온다.\n",
        "corpus.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ko</th>\n",
              "      <th>en</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>다만 지난 7월부터 수면 무호흡증 진단을 위한 수면다원검사와 치료에 필요한 양압기 ...</td>\n",
              "      <td>However, since July, as health insurance (20% ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>하지만 몇몇 사람들은 그 표현이 관용구인지 알아차리지 못합니다.</td>\n",
              "      <td>Some people, however, cant recognize that it w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>끈끈한 승부근성으로 찬스에서 더 영양가 만점의 활약을 하는 오재원이 있기에 선두질주...</td>\n",
              "      <td>The Doosan Bears are gaining momentum in the l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>협약내용은 삼성화재서비스손해사정㈜에서 매월 임직원들의 기부를 통해 향후 3년간 30...</td>\n",
              "      <td>The contents of the agreement are to support m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>이 같은 대중적 관심을 겨냥해 이동통신사가 발 빠르게 움직였다.</td>\n",
              "      <td>In response to such public interest, mobile op...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>달러보험은 원화상품 대비 달러가 갖는 경쟁력을 바탕으로 고객가치를 높인 상품으로, ...</td>\n",
              "      <td>The dollar insurance is a product that heighte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>극 중 커플로 등장했던 박경림과 조인성이 사석에서 술잔을 기울이 박경림의 절친인 장...</td>\n",
              "      <td>Park Kyung-rim and Jo In-sung, who appeared as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>제1 야당이 극우 인사의 해괴망측한 주장에 멍석을 깔아주고, 함께 장단을 맞췄는데 ...</td>\n",
              "      <td>The main opposition party dug up the weird cla...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>금융규제에 발이 묶여 시장 진입 자체가 힘든 상황이 지속되자 국회와 정부 부처가 모...</td>\n",
              "      <td>As financial regulations continue to make it d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1년 이상의 파트 타임 경험이 있습니다.</td>\n",
              "      <td>I have an experience of part time job longer t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  ko  ... Label\n",
              "0  다만 지난 7월부터 수면 무호흡증 진단을 위한 수면다원검사와 치료에 필요한 양압기 ...  ...     0\n",
              "1                하지만 몇몇 사람들은 그 표현이 관용구인지 알아차리지 못합니다.  ...     0\n",
              "2  끈끈한 승부근성으로 찬스에서 더 영양가 만점의 활약을 하는 오재원이 있기에 선두질주...  ...     1\n",
              "3  협약내용은 삼성화재서비스손해사정㈜에서 매월 임직원들의 기부를 통해 향후 3년간 30...  ...     0\n",
              "4                이 같은 대중적 관심을 겨냥해 이동통신사가 발 빠르게 움직였다.  ...     1\n",
              "5  달러보험은 원화상품 대비 달러가 갖는 경쟁력을 바탕으로 고객가치를 높인 상품으로, ...  ...     0\n",
              "6  극 중 커플로 등장했던 박경림과 조인성이 사석에서 술잔을 기울이 박경림의 절친인 장...  ...     1\n",
              "7  제1 야당이 극우 인사의 해괴망측한 주장에 멍석을 깔아주고, 함께 장단을 맞췄는데 ...  ...     1\n",
              "8  금융규제에 발이 묶여 시장 진입 자체가 힘든 상황이 지속되자 국회와 정부 부처가 모...  ...     1\n",
              "9                             1년 이상의 파트 타임 경험이 있습니다.  ...     0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSND6easp5Rk"
      },
      "source": [
        "# 문장과 Label 추출\n",
        "text = corpus['ko']\n",
        "label = corpus['Label']\n",
        "\n",
        "# Label 개수 변수 지정 (단순히 2를 값으로 집어 넣어도 됨)\n",
        "n_topic = len(set(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJMzKWzC1hcN",
        "outputId": "831012f8-5496-4e46-f299-ace5a8a4a8f7"
      },
      "source": [
        "# 관용구 데이터와 관용구가 아닌 데이터의 비율이 1:1인지 확인\n",
        "label.sum(), label.sum()/len(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3376, 0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDHwecn8LBFb"
      },
      "source": [
        "## 2-2) Train/Test/Validation 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckXqHJNVyiey"
      },
      "source": [
        "# Train 데이터와 Test 데이터 분리 (분리 비율은 `train_test_split_ratio`에서 설정 가능)\n",
        "x_train, x_test, y_train, y_test = train_test_split(text, label, test_size=train_test_split_ratio, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L33wZM3MZL8"
      },
      "source": [
        "## 2-3) Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTKBQ4XVsGwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b60828-dded-4a5c-b4a9-31700f891605"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(tex) + \" [SEP]\" for tex in x_train]\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 나무들이 우리를 돕는 여러 방법이 있습니다. [SEP]',\n",
              " '[CLS] 소득주도 경제가 탄력을 받으려면 일자리가 증가할 수 있도록 산업 구조 개선과 연구개발(R&D) 지원이 있어야 한다. [SEP]',\n",
              " '[CLS] 특히 자극적인 대중음악의 트렌드는 점점 음악 속에서 ‘사람’을 지웠고, 몸이 먼저 반응하기 시작하며 따뜻했던 음악의 미덕은 설 자리를 잃었다. [SEP]',\n",
              " '[CLS] 높은 인건비는 차치하더라도 사사건건 기업 경영의 발목을 잡는 노조도 기업들이 해외로 눈을 돌리는 원인으로 꼽힌다. [SEP]',\n",
              " '[CLS] 내가 가지고 있는 소유를 팔아 구제해서 마련해야 합니다. [SEP]',\n",
              " '[CLS] 은행권 노사가 공동으로 2000억원대 규모의 공익재단을 만들기로 했다. [SEP]',\n",
              " '[CLS] 조금 전에 결제한 카드랑 영수증은 여기에 있어요. [SEP]',\n",
              " '[CLS] 교육감들이 교육부 개혁방향과 공통분모를 찾아 손발을 맞춰야 하는 이유다. [SEP]',\n",
              " '[CLS] 귀환 후 외가가 있던 경주에서 살다가 아이가 있는 홀아비와 결혼하였으나 남편이 일찍 사망하였다. [SEP]',\n",
              " '[CLS] 롯데그룹이 최근 실적 악화로 골치를 앓고 있는 롯데마트의 신임 대표에 문영표(사진) 롯데글로벌로지스 대표를 구원 등판시키며 새로운 활력을 꾀한다. [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeXrqpRaBjOX"
      },
      "source": [
        "### ***Referce Code 설명 인용1***\n",
        "- BERT의 입력은 아래 그림과 같은 형식\n",
        "\n",
        "![대체 텍스트](https://mino-park7.github.io/images/2019/02/bert-input-representation.png)\n",
        "\n",
        "- Classification을 뜻하는 [CLS] 심볼이 제일 앞에 삽입\n",
        " - 파인튜닝시 출력에서 이 위치의 값을 사용하여 분류를 수행\n",
        "- [SEP]은 Seperation을 가리키며 두 문장을 구분하는 역할\n",
        " - 본 예측에서는 문장이 하나이므로 [SEP]도 하나만 넣어서 진행\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33CyZK5Js5Qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1832f6-82a6-4573-c952-0f09f90c9b04"
      },
      "source": [
        "# 라벨 추출\n",
        "labels = y_train.values\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "700abd0a16144906ae0060b498bf6162",
            "a3501b0ea7124bbd89055ffe1de0d1c2",
            "493ac1f267f24f85b719ded49934e746",
            "f3c7fcdb77f34e25921a52ba836caf84",
            "644c9126d938477d9beea2d5b222b181",
            "a6944d9102f34d71852190dfda7eead5",
            "4d01561bc73d43cd88bfe72a28048fd1",
            "42e12a6362eb46abadbd2f2bbceb8e39",
            "ddbd33aa675b4d94973af0c383133043",
            "97490835ada74e47859533581fd9dd35",
            "8bfa2690e8ac405a84ef87d4da821449"
          ]
        },
        "id": "IndTSH6ssTS4",
        "outputId": "fcb83286-9818-42a7-e731-ec0104fec9fb"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name, cache_dir='bert_kor_ckpt', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "700abd0a16144906ae0060b498bf6162",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 나무들이 우리를 돕는 여러 방법이 있습니다. [SEP]\n",
            "['[CLS]', '나', '##무', '##들이', '우', '##리를', '돕', '##는', '여러', '방', '##법', '##이', '있', '##습', '##니다', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6SRXmlTMjr"
      },
      "source": [
        "### ***Referce Code 설명 인용2***\n",
        "\n",
        "- BERT는 형태소분석으로 토큰을 분리하지 않고 WordPiece라는 통계적인 방식을 사용\n",
        "- 한 단어내에서 자주 나오는 글자들을 붙여서 하나의 토큰으로 만듦\n",
        "    - 언어에 상관없이 토큰을 생성할 수 있다는 장점\n",
        "    - 신조어 같이 사전에 없는 단어 처리 용이\n",
        "\n",
        "- 위의 결과에서 ## 기호는 앞 토큰과 이어진다는 표시\n",
        "- 토크나이저는 여러 언어의 데이터를 기반으로 만든 bert-base-multilingual-cased'를 사용. → 한글도 처리가 가능\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEA6Ch7Zslh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1925342f-9ef4-4ea8-fca6-85d729897bb0"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = max_len_value\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   8982,  32537,  20173,   9604,  27852,   9093,  11018,\n",
              "        30085,   9328,  33768,  10739,   9647, 119081,  48345,    119,\n",
              "          102,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHI53Jt8VrY8"
      },
      "source": [
        "### ***Referce Code 설명 인용3***\n",
        "\n",
        "- 보통 딥러닝 모델에는 토큰 자체를 입력으로 넣을 수 없음\n",
        "- 임베딩 레이어에는 토큰을 숫자로 된 인덱스로 변환하여 사용함\n",
        "- BERT의 토크나이저는 {단어토큰:인덱스}로 구성된 단어사전을 가지고 있으며, 이를 참조하여 토큰을 인덱스로 변환하는 과정을 수행\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxczSGIQstxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bc7edf-33f3-4cdd-c195-30a8541c5df1"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxvw0OVAsv29"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=2018, \n",
        "                                                                                    test_size=train_val_split_ratio)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018, \n",
        "                                                       test_size=train_val_split_ratio)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_QRo7z_tBee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc357a75-98f1-4874-99f0-52a202006f84"
      },
      "source": [
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   8885,  30858,  18623,   8922,  66554,   9711,  88168,   9531,\n",
            "        118802,  11664,   9323, 101322,  10530,   9368,  10739,   9141,  46572,\n",
            "          9519,  46861,  16439,  50632,  28000,   9998,  12945,   9776,  10892,\n",
            "          8996,  14646,   9460, 119081,  10530,   9521,  18784, 119471,  10622,\n",
            "          9511,  11664,  13767,   9283,  37114, 119031,  11903,    119,    102,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([  101,  9954,  9485, 36553, 10739,  9484, 27852,  8932, 14279, 37341,\n",
            "         9854, 63243, 29669, 10017, 27023, 11664, 11506,   119,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iibX8NRjtCQk"
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVxQLWgw04cF"
      },
      "source": [
        "# **3. 전처리 - 테스트셋**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLnE4h0oPAh5"
      },
      "source": [
        "### 3-1) Encoding\n",
        "- 2장 전처리 - 훈련셋 / 2-3) Encoding와 동일한 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOO398sT05Fr"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in x_test]\n",
        "# sentences[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4fEYAM51Fhu"
      },
      "source": [
        "# 라벨 추출\n",
        "labels = y_test.values\n",
        "# labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4iuascb1KNh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "8ea85632c69d48f1afcfcd1930779ecd",
            "21c1e9340c284689967087a97c0f7d30",
            "a576e08685a44c90839c12cc28c9c44a",
            "980c1d37218c488e8c51dcd2517c3507",
            "303d426f5dee4f63b15a034d11c152b5",
            "a25b863106594f73987e76c258f39631",
            "9068904d8fc64a0299d6be2d6efcba51",
            "5af9cef0eaa341bc9599243bc71c9daf",
            "ea4d38fd6963432992b2644312b34228",
            "b145a0e915e644288078aa08908b8823",
            "c2a400c93b6c4003bf71e21392691599",
            "541b9048e0bb42f18c4c63b4cd9b1ddf",
            "2dc016ceffb641b0b1a0a827a091258e",
            "e2774c2fc5ea443396ce710fb0575ef3",
            "69f9ef83390c45e38700683c01b9f30b",
            "98f19768b2b143aa87b38952bb0b2560",
            "112c4965cc4c47f4992de4e89e8e1e76",
            "8820ed23f207428a9daa22a18ee13c98",
            "273a965090684e7895a3d8abcc1c0a80",
            "7a721774e6174273bb3cb45fab11c25f",
            "b90afa24eaf841ea9006c392ccf209b9",
            "08dd33675a064578ab413cde352c264e",
            "15d19606ace34666870f39b64c9c5941",
            "47ca6cef0e4b4cca9fb63d42e87ed6bc",
            "aadf86b54df944ab89e2d51002cce1f5",
            "f3f9a4b709874501a48e37b06caea424",
            "224156d8a7b44fd7a25497770229b59c",
            "aa9e6fecd6d24d15bd11c905d661971b",
            "4fa34294a35f4acb8b0f56725ac994ad",
            "e462544d05334bcc8ed82477168c8e60",
            "86029eeff2d74ff59d0a6b541c901319",
            "b476a57efb554d5e8e9879d5272a6531",
            "7d68ab5c6b3e448a85184e0c3d1a57ce"
          ]
        },
        "outputId": "152fcc45-33f9-4c57-8316-dbdb086541cb"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=False)\n",
        "# tokenizer = RobertaTokenizer.from_pretrained(bert_model_name, do_lower_case=False)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained(bert_model_name, do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ea85632c69d48f1afcfcd1930779ecd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "541b9048e0bb42f18c4c63b4cd9b1ddf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15d19606ace34666870f39b64c9c5941",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 김장언 미술 큐레이터를 비롯해 김남수 무용평론가, 영화이론을 전공한 임경용 더북소사이어티 대표 등 다양한 분야의 전문가들이 머리를 맞댔다. [SEP]\n",
            "['[CLS]', '김', '##장', '##언', '미', '##술', '큐', '##레', '##이터', '##를', '비', '##롯', '##해', '김', '##남', '##수', '무', '##용', '##평', '##론', '##가', ',', '영화', '##이', '##론', '##을', '전', '##공', '##한', '임', '##경', '##용', '더', '##북', '##소', '##사', '##이어', '##티', '대', '##표', '등', '다양한', '분', '##야', '##의', '전', '##문', '##가', '##들이', '머', '##리를', '[UNK]', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRyGx6Om1S6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ad7c27-26ee-4e29-cd1d-3bd108c04357"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = max_len_value\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   8935,  13890,  48036,   9309,  51945,   9832,  56645,\n",
              "        85297,  11513,   9379, 118885,  14523,   8935,  37004,  15891,\n",
              "         9294,  24974, 119398,  42769,  11287,    117,  42428,  10739,\n",
              "        42769,  10622,   9665,  28000,  11102,   9644,  31720,  24974,\n",
              "         9074,  82512,  22333,  12945,  86732,  45725,   9069,  37824,\n",
              "         9121,  53645,   9367,  21711,  10459,   9665,  25934,  11287,\n",
              "        20173,   9265,  27852,    100,    119,    102,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfu0uy_K1ZGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619c0801-62f7-49c1-e2b1-dd36ead1a0d5"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNQ6mYQF1cxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddd1f8b-5f2f-4f22-a5d1-3a39d8eeeb70"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   8935,  13890,  48036,   9309,  51945,   9832,  56645,  85297,\n",
            "         11513,   9379, 118885,  14523,   8935,  37004,  15891,   9294,  24974,\n",
            "        119398,  42769,  11287,    117,  42428,  10739,  42769,  10622,   9665,\n",
            "         28000,  11102,   9644,  31720,  24974,   9074,  82512,  22333,  12945,\n",
            "         86732,  45725,   9069,  37824,   9121,  53645,   9367,  21711,  10459,\n",
            "          9665,  25934,  11287,  20173,   9265,  27852,    100,    119,    102,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzyPkOO2kOe"
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bI7xp9SuVNk"
      },
      "source": [
        "# **4. 모델 생성**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YBHeI9oPU9d"
      },
      "source": [
        "## 4-1) GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-fKPcyouU3U",
        "outputId": "da627ffb-2dcd-4f53-9a89-d81c6d9437c0"
      },
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF_cpbnxvGGt",
        "outputId": "da0dced7-af0b-4577-c026-2b15d641b959"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxpdZjHnQ2Ir"
      },
      "source": [
        "## 4-2) BERT Model 생성\n",
        "\n",
        "- 만약 Binary Classification이 아닌 다중 분류일 경우 `BertForSequenceClassification.from_pretrained`의 `num_labels`의 수 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "10f0fb43a4ee4b8a9529ca4332d14ebb",
            "e1e11df604464c759aec67a397c90955",
            "c3fadae2265f47929b85d237bf79d9da",
            "b2b47a6e29ac4a36843dd4b0da983770",
            "01d1e416dd5d4d3bb268b5361eb11799",
            "e100fa10d2884e078800c7cc6f6465cb",
            "18e64c069f98494e9d38696a34d86221",
            "2928be1e71194537a54d5c496369eb7a",
            "348df742e8fa4163af74f013de78f08e",
            "6612e954d5ad4733b74031a2b4e3efe6",
            "213b0a1bad0d4c5b842cf41bfde798c8"
          ]
        },
        "id": "W8frZIzkvMmj",
        "outputId": "ebf8e2be-bcb4-4784-bca6-882a0bdd93ca"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(bert_model_name, num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10f0fb43a4ee4b8a9529ca4332d14ebb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlszxDr6h8GP"
      },
      "source": [
        "### ***Referce Code 설명 인용4***\n",
        "\n",
        "- 사전훈련된 BERT는 다양한 문제로 ***전이학습***이 가능\n",
        "- 본 코드에서는 아래 그림과 같이 한 문장을 분류하는 방법을 사용\n",
        "\n",
        "![대체 텍스트](http://www.mccormickml.com/assets/BERT/padding_and_mask.png)\n",
        "\n",
        "- 관용구 문장이 입력으로 들어가면 긍정(관용구ㅇ)/부정(관용구x)으로 구분\n",
        "- 모델의 출력에서 [CLS] 위치인 첫 번째 토큰에 새로운 레이어를 붙여서 ***파인튜닝***을 수행\n",
        "- Huggning Face는 **[BertForSequenceClassification()](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification)** 함수를 제공하기 때문에 쉽게 구현 가능\n",
        "    - BertForSequenceClassification 추가 설명 사이트 [↩](https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d)\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUrQPTZ9tvX3"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate, # 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = epochs_value\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk310sQtwkti"
      },
      "source": [
        "# **5. 모델 학습**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Kl5M0_G6JS"
      },
      "source": [
        "## 5-1) 성능 평가 함수 생성\n",
        "- Accuracy, Precision, Recall, F1 Score를 계산하기 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZEmVW6kwmf7"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXjBzNKGx6v"
      },
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "    precision = precision_score(pred_flat, labels_flat)\n",
        "    recall = recall_score(pred_flat, labels_flat)\n",
        "    f1score = f1_score(pred_flat, labels_flat)\n",
        "    return accuracy, precision, recall, f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxlXEBA0WefL"
      },
      "source": [
        "## 5-2) 학습 수행\n",
        "- 에폭마다 훈련셋과 검증셋을 반복하여 학습을 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wevx0H3hwutH"
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhkN2YDQwwiP",
        "outputId": "053d2754-1f43-4c7c-ccbd-8e24794da2ef"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy, _, _, _ = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovOGqnzwdeNr"
      },
      "source": [
        "# 모델 저장\n",
        "torch.save(model, './model/BERT_multilingual_pytorch.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b40rub92wGa"
      },
      "source": [
        "# **6. 테스트셋 평가**\n",
        "- 2장 전처리 - 훈련셋 / 2-2) Train/Test/Validation의 Test Data에 대한 성능 평가 과정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soXHS1OC26Ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fea23d2-ee42-4efa-ee9a-9b2fd70d1046"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy, eval_precision, eval_recall, eval_f1score = 0, 0, 0, 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy, tmp_eval_precision, tmp_eval_recall, tmp_eval_f1score = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    eval_precision += tmp_eval_precision\n",
        "    eval_recall += tmp_eval_recall\n",
        "    eval_f1score += tmp_eval_f1score\n",
        "\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Precision: {0:.3f}\".format(eval_precision/nb_eval_steps))\n",
        "print(\"Recall: {0:.3f}\".format(eval_recall/nb_eval_steps))\n",
        "print(\"Accuracy: {0:.3f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"f1_score: {0:.3f}\".format(eval_f1score/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precision: 0.890\n",
            "Recall: 0.877\n",
            "Accuracy: 0.885\n",
            "f1_score: 0.874\n",
            "Test took: 0:00:09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIkWEx-M2w3Y"
      },
      "source": [
        "# **7. 새로운 문장 테스트**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeMlzctU9ij6"
      },
      "source": [
        "## 7-1) Dataset Load\n",
        "\n",
        "- 경우 1\n",
        "```python\n",
        "new_test = pd.read_csv('./data/new_idiom_dataset(100).csv')\n",
        "```\n",
        "    - 뉴스 기사에서 선별한 관용구가 없는 문장 50개\n",
        "    - 국립국어원 표준국어대사전에 수록된 관용구 예문 50문장 (ㄱ~ㅎ까지 고르게 선별)\n",
        "\n",
        "- 경우 2\n",
        "```python\n",
        "with open('./data/test_3000.pkl', 'rb') as f:\n",
        "    new_test = pickle.load(f)\n",
        "```\n",
        "    - Step 3)의 Dataset Case 1 & 2의 검증셋: 1,500개(관용구 o) + 1,500개(관용구 x)는 모두 동일\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0pxLMwS9jSv"
      },
      "source": [
        "# 데이터 로드\n",
        "new_test = pd.read_csv('./data/new_idiom_dataset(100).csv')\n",
        "\n",
        "# with open('./data/test_3000.pkl', 'rb') as f:\n",
        "#   new_test = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE2VM2DoEMW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9438c3d8-d22b-40f0-8cd4-f66ee104b4f9"
      },
      "source": [
        "# 데이터 정보 확인\n",
        "new_test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   ko      100 non-null    object\n",
            " 1   Label   100 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM-V5VpPVNRD"
      },
      "source": [
        "## 7-2) BERT Model Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PYppZHF9jSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0f6b50-ecf3-46cc-b577-d7f54beb1d23"
      },
      "source": [
        "# 모델 로드\n",
        "test_model = torch.load('./model/BERT_multilingual_pytorch.model')\n",
        "test_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxiadJ_7KnxO"
      },
      "source": [
        "## 7-3) 전처리 및 Encoding\n",
        "- 2장 전처리 - 훈련셋 과정과 동일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8oBy1JXVhOH"
      },
      "source": [
        "### 쓰이지 않는듯한 코드들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4v_VfEfGQB"
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = max_len_value\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C12NL1Fvgv4E"
      },
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qqdFr-SVmSO"
      },
      "source": [
        "### 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2xeLsk9jSx"
      },
      "source": [
        "nex_text_ko = new_test['ko']\n",
        "new_text_label = new_test['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MduSF3sD9jSy"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in nex_text_ko]\n",
        "# sentences[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wprg1m89jSy"
      },
      "source": [
        "# 라벨 추출\n",
        "labels = new_text_label.values\n",
        "# labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbJ7uVMr9jSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55129674-a573-498c-d373-f7f7c6937dc5"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 윤석열 전 총장이 검찰총장으로 재직하던 지난해 총선 직전, 검찰이 국민의힘의 전신인 미래통합당을 통해 여권 정치인들에 대한 고발을 요청했다는 의혹이 제기됐습니다.  [SEP]\n",
            "['[CLS]', '윤', '##석', '##열', '전', '총', '##장이', '검', '##찰', '##총', '##장으로', '재', '##직', '##하던', '지', '##난', '##해', '총', '##선', '직', '##전', ',', '검', '##찰', '##이', '국', '##민', '##의', '##힘', '##의', '전', '##신', '##인', '미', '##래', '##통', '##합', '##당', '##을', '통해', '여', '##권', '정', '##치', '##인', '##들', '##에', '대한', '고', '##발', '##을', '요', '##청', '##했다', '##는', '의', '##혹', '##이', '제', '##기', '##됐', '##습', '##니다', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMaY7NF9jSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1362f985-d870-4b91-bb0e-913f3bc7afcc"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = max_len_value\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9627,  40958,  79604,   9665,   9761,  55635,   8868,\n",
              "        99118, 119270,  66896,   9659,  33077,  76424,   9706,  33305,\n",
              "        14523,   9761,  18471,   9707,  16617,    117,   8868,  99118,\n",
              "        10739,   8909,  36553,  10459, 119471,  10459,   9665,  25387,\n",
              "        12030,   9309,  37388,  43022,  33188,  21928,  10622,  25605,\n",
              "         9565,  25347,   9670,  18622,  12030,  27023,  10530,  18154,\n",
              "         8888,  51431,  10622,   9599,  40311,  12490,  11018,   9637,\n",
              "       119438,  10739,   9672,  12310, 118799, 119081,  48345,    119])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oom90RI09jS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e014ce3-be9b-4fa3-f476-f38906579bc8"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiiQg47f9jS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f9f8b47-f385-4d5b-84d2-18f0ab0ca7af"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   9627,  40958,  79604,   9665,   9761,  55635,   8868,  99118,\n",
            "        119270,  66896,   9659,  33077,  76424,   9706,  33305,  14523,   9761,\n",
            "         18471,   9707,  16617,    117,   8868,  99118,  10739,   8909,  36553,\n",
            "         10459, 119471,  10459,   9665,  25387,  12030,   9309,  37388,  43022,\n",
            "         33188,  21928,  10622,  25605,   9565,  25347,   9670,  18622,  12030,\n",
            "         27023,  10530,  18154,   8888,  51431,  10622,   9599,  40311,  12490,\n",
            "         11018,   9637, 119438,  10739,   9672,  12310, 118799, 119081,  48345,\n",
            "           119])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmxHtLzj9jS1"
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = batch_size_value\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNaD0TVYRO6I"
      },
      "source": [
        "## 7-4) 테스트셋 평가\n",
        "- 6장 테스트셋 평가 과정과 동일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvndao9j9jS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b99111-a6b7-4556-e6c9-02beedcf4607"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy, eval_precision, eval_recall, eval_f1score = 0, 0, 0, 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy, tmp_eval_precision, tmp_eval_recall, tmp_eval_f1score = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    eval_precision += tmp_eval_precision\n",
        "    eval_recall += tmp_eval_recall\n",
        "    eval_f1score += tmp_eval_f1score\n",
        "\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Precision: {0:.3f}\".format(eval_precision/nb_eval_steps))\n",
        "print(\"Recall: {0:.3f}\".format(eval_recall/nb_eval_steps))\n",
        "print(\"Accuracy: {0:.3f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"f1_score: {0:.3f}\".format(eval_f1score/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precision: 0.901\n",
            "Recall: 0.894\n",
            "Accuracy: 0.896\n",
            "f1_score: 0.897\n",
            "Test took: 0:00:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKQr6WB3ECh_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}