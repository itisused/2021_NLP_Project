{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final Idiom Classifier for KoGPT2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y82msoNJXUiZ"
      },
      "source": [
        "# KoGPT2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzF-3I-LW0QM"
      },
      "source": [
        "!pip install --upgrade mxnet>=1.6.0\n",
        "!pip install gluonnlp\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "import gluonnlp as nlp\n",
        "from gluonnlp.data import SentencepieceTokenizer, SentencepieceDetokenizer\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import save_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJs-AjZQW4G2"
      },
      "source": [
        "import pickle\n",
        "#with open('./final_idiom_dataset_for_ko.pkl', 'rb') as f:\n",
        "with open('./2/train_34614.pkl','rb') as f:\n",
        "  text = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y27YQT3dW-W2"
      },
      "source": [
        "dx_train,dx_test, dy_train, dy_test = train_test_split(data, target, test_size=0.2, stratify=target, random_state=42)\n",
        "\n",
        "MY_PATH = '/content/drive/MyDrive/Colab Notebooks/multicampus/Idiom Classifier/4.KoGPT2/'\n",
        "MODEL_PATH = MY_PATH + 'gpt_ckpt'\n",
        "TOKENIZER_PATH = MY_PATH + 'gpt_ckpt/gpt2_kor_tokenizer.spiece'\n",
        "\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH, num_best=0, alpha=0)\n",
        "detokenizer = SentencepieceDetokenizer(TOKENIZER_PATH)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n",
        "                                               mask_token = None,\n",
        "                                               sep_token = None,\n",
        "                                               cls_token = None,\n",
        "                                               unknown_token = '<unk>',\n",
        "                                               padding_token = '<pad>',\n",
        "                                               bos_token = '<s>',\n",
        "                                               eos_token = '</s>')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uswJEOeIW_Sd"
      },
      "source": [
        "MAX_LEN = 60\n",
        "def build_data(x_data, y_label):\n",
        "    data_sents = []\n",
        "    data_labels = []\n",
        "\n",
        "    for sent, label in zip(x_data, y_label):\n",
        "        tokenized_text = vocab[tokenizer(sent)]\n",
        "\n",
        "        tokens = [vocab[vocab.bos_token]]\n",
        "        tokens += pad_sequences([tokenized_text], \n",
        "                                MAX_LEN, \n",
        "                                value=vocab[vocab.padding_token], \n",
        "                                padding='post').tolist()[0] \n",
        "        tokens += [vocab[vocab.eos_token]]\n",
        "\n",
        "        data_sents.append(tokens)\n",
        "        data_labels.append(label)\n",
        "\n",
        "    return np.array(data_sents, dtype=np.int64), np.array(data_labels, dtype=np.int64).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHNYrmOpXALm"
      },
      "source": [
        "x_train, y_train = build_data(dx_train, dy_train)\n",
        "x_test, y_test = build_data(dx_test, dy_test)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cyh0evZXBC-"
      },
      "source": [
        "gpt_model = TFGPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
        "gpt_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c0Z9IGmXB12"
      },
      "source": [
        "gpt_model.trainable = True\n",
        "gpt_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpXqr7nqXCm2"
      },
      "source": [
        "x_input = Input(batch_shape = (None, MAX_LEN + 2), dtype = tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uIGLUSrXDZv"
      },
      "source": [
        "output_gpt = gpt_model(x_input)[0][:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OV6N7ghXEKP"
      },
      "source": [
        "y_output = Dense(1, activation = 'sigmoid')(output_gpt)\n",
        "model = Model(x_input, y_output)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 2e-5))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAsDMTgVXE5G"
      },
      "source": [
        "hist = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=3, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmaqjfsqXFsG"
      },
      "source": [
        "gpt_model.trainable = False\n",
        "gpt_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT3BjXf7XGY2"
      },
      "source": [
        "model = Model(x_input, y_output)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 1e-6))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4kuptO-XHFu"
      },
      "source": [
        "hist = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=3, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwgGipOWXytR"
      },
      "source": [
        "## Predict(Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpQ8SAh0X4J3"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/multicampus/Idiom Classifier/data\n",
        "import pickle\n",
        "with open('./2/test_3000.pkl', 'rb') as f:\n",
        "  new_test = pickle.load(f)\n",
        "new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWFg4TXpX8Fe"
      },
      "source": [
        "new_test['ko'][10]\n",
        "new_test = new_test.sample(frac=1).reset_index(drop=True)\n",
        "new_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO1oLeimX_NX"
      },
      "source": [
        "new_test_text, _ = build_data(new_test['ko'], np.zeros(len(new_test)))\n",
        "answer = new_test.Label.to_list()\n",
        "len(answer)\n",
        "# 시험 데이터로 학습 성능을 평가한다\n",
        "new_pred = model.predict(new_test_text)\n",
        "new_y_pred = np.where(new_pred > 0.5, 1, 0)\n",
        "#new_accuracy = (new_y_pred == answer).mean()\n",
        "#print(\"\\nAccuracy = %.2f %s\" % (accuracy * 100, '%'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb09D_psYAUo"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
        "# 오차행렬\n",
        "\n",
        "# 정확도\n",
        "print(\"accuracy:\", accuracy_score(answer, new_y_pred))\n",
        "\n",
        "# 정밀도\n",
        "print(\"precision:\", precision_score(answer, new_y_pred))\n",
        "\n",
        "# 재현율\n",
        "print(\"recall:\", recall_score(answer, new_y_pred))\n",
        "\n",
        "# f1-score\n",
        "print(\"F1-Score:\", f1_score(answer, new_y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}